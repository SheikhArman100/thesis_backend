{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAxcuA951NC9",
        "outputId": "f041c8fb-7769-41a2-dec5-a1819a4f75ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Collecting pyquery\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from requests_html) (2.25.1)\n",
            "Collecting parse\n",
            "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fake-useragent\n",
            "  Downloading fake_useragent-1.1.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyppeteer>=0.0.14\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.8/dist-packages (from requests_html) (0.0.1)\n",
            "Collecting w3lib\n",
            "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
            "Collecting urllib3<2.0.0,>=1.25.8\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests_html) (6.0.0)\n",
            "Collecting websockets<11.0,>=10.0\n",
            "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2021 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests_html) (2022.12.7)\n",
            "Collecting pyee<9.0.0,>=8.1.0\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.8/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: importlib-resources>=5.0 in /usr/local/lib/python3.8/dist-packages (from fake-useragent->requests_html) (5.10.2)\n",
            "Collecting cssselect>=1.2.0\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.8/dist-packages (from pyquery->requests_html) (4.9.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->requests_html) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.11.0)\n",
            "Building wheels for collected packages: parse\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.19.0-py3-none-any.whl size=24591 sha256=a9564384eda0802bbba600b37e51835c2e9706cfbd1af990371c86828e4e4c02\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/33/1f/68392720485b3ecf125a69e700baaab7624616deedea2fa6e2\n",
            "Successfully built parse\n",
            "Installing collected packages: pyee, parse, websockets, w3lib, urllib3, cssselect, pyquery, pyppeteer, fake-useragent, requests_html\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed cssselect-1.2.0 fake-useragent-1.1.1 parse-1.19.0 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests_html-0.10.0 urllib3-1.26.14 w3lib-2.1.1 websockets-10.4\n"
          ]
        }
      ],
      "source": [
        "!pip install requests_html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XN58bLxP1zO6",
        "outputId": "cb70359f-1b72-46ee-882d-fd3940fd0cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting page: 400\n",
            "total results:27\n",
            "Getting page: 401\n",
            "total results:54\n"
          ]
        }
      ],
      "source": [
        "from requests_html import HTMLSession\n",
        "import csv\n",
        "\n",
        "s = HTMLSession()\n",
        "base_url = \"https://bikroy.com\"\n",
        "\n",
        "\n",
        "def get_products_links(page):\n",
        "    url = f\"https://bikroy.com/en/ads/bangladesh/cars?sort=date&order=desc&buy_now=0&urgent=0&page={page}\"\n",
        "    links = []\n",
        "    r = s.get(url)\n",
        "    # print(r.status_code)\n",
        "    products = r.html.find('ul.list--3NxGO li')\n",
        "    for item in products:\n",
        "        item_link = item.find('a', first=True).attrs[\"href\"]\n",
        "        full_link = f\"{base_url}{item_link}\"\n",
        "        links.append(full_link)\n",
        "    return links\n",
        "\n",
        "\n",
        "def product_info(url_link):\n",
        "    r = s.get(url_link)\n",
        "    car_name = r.html.find('h1.title--3s1R8', first=True).text.strip()\n",
        "    ##other info\n",
        "    brand = \"\",\n",
        "    model = \"\",\n",
        "    trim=\"\"\n",
        "    manufacture_year = \"\",\n",
        "    condition = \"\",\n",
        "    transmission = \"\",\n",
        "    body_type = \"\",\n",
        "    fuel_type = \"\"\n",
        "    engine_capacity = \"\"\n",
        "    mileage = \"\"\n",
        "    info_list = []\n",
        "    all_info = r.html.find('div.word-break--2nyVq.value--1lKHt')\n",
        "    for info in all_info:\n",
        "        info_list.append(info.text.strip())\n",
        "    if len(info_list) == 11:\n",
        "        # brand\n",
        "        brand = info_list[0],\n",
        "        brand = \"\".join(brand)\n",
        "        # model\n",
        "        model = info_list[1],\n",
        "        model = \"\".join(model)\n",
        "        #trim\n",
        "        trim = info_list[2],\n",
        "        trim = \"\".join(trim)\n",
        "        # year\n",
        "        manufacture_year = info_list[3],\n",
        "        manufacture_year = \"\".join(manufacture_year)\n",
        "        # condition\n",
        "        condition = info_list[5],\n",
        "        condition = \"\".join(condition)\n",
        "        # transmission\n",
        "        transmission = info_list[6],\n",
        "        transmission = \"\".join(transmission)\n",
        "        # body_type\n",
        "        body_type = info_list[7],\n",
        "        body_type = \"\".join(body_type)\n",
        "        #fuel_type\n",
        "        fuel_type = info_list[8],\n",
        "        fuel_type = \"\".join(fuel_type)\n",
        "        # engine_capacity-----\n",
        "        engine_capacity = info_list[9]\n",
        "        engine_capacity = \"\".join(engine_capacity)\n",
        "\n",
        "        # mileage-----\n",
        "        mileage = info_list[10]\n",
        "        mileage = \"\".join(mileage)\n",
        "    elif len(info_list) == 10:\n",
        "        # brand\n",
        "        brand = info_list[0],\n",
        "        brand = \"\".join(brand)\n",
        "        # model\n",
        "        model = info_list[1],\n",
        "        model = \"\".join(model)\n",
        "        #trim\n",
        "        trim = info_list[2]\n",
        "        trim = \"\".join(trim)\n",
        "        # year\n",
        "        manufacture_year = info_list[3],\n",
        "        manufacture_year = \"\".join(manufacture_year)\n",
        "        # condition\n",
        "        condition = info_list[4],\n",
        "        condition = \"\".join(condition)\n",
        "        # transmission\n",
        "        transmission = info_list[5],\n",
        "        transmission = \"\".join(transmission)\n",
        "        # body_type\n",
        "        body_type = info_list[6],\n",
        "        body_type = \"\".join(body_type)\n",
        "        fuel_type = info_list[7],\n",
        "        fuel_type = \"\".join(fuel_type)\n",
        "        # engine_capacity-----\n",
        "        engine_capacity = info_list[8]\n",
        "        engine_capacity = \"\".join(engine_capacity)\n",
        "\n",
        "        # mileage-----\n",
        "        mileage = info_list[9]\n",
        "        mileage = \"\".join(mileage)\n",
        "    elif len(info_list)>11:\n",
        "        return\n",
        "\n",
        "    # price-----\n",
        "    price = r.html.find('div.amount--3NTpl', first=True).text.strip()\n",
        "\n",
        "    # description-----\n",
        "    description_Sentences = r.html.find('div.description--1nRbz p')\n",
        "    description = \"\"\n",
        "    for sentence in description_Sentences:\n",
        "        sentence_detail = sentence.text.strip()\n",
        "        description += sentence_detail\n",
        "    shop_info=r.html.find(\"div.card--_2NNk.card--_2NNk\", first=True).text.strip()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    product = {\n",
        "        'CarName': car_name,\n",
        "        'brand': brand,\n",
        "        'model': model,\n",
        "        'trim':trim,\n",
        "        'manufacture_year': manufacture_year,\n",
        "        \"condition\": condition,\n",
        "        'transmission': transmission,\n",
        "        'body_type': body_type,\n",
        "        'fuel_type': fuel_type,\n",
        "        'engine_capacity': engine_capacity,\n",
        "        'mileage': mileage,\n",
        "        'price': price,\n",
        "        'description': description,\n",
        "        \"shop_info\":shop_info\n",
        "    }\n",
        "    return product\n",
        "\n",
        "\n",
        "def save_csv(results):\n",
        "    columns = results[0].keys()\n",
        "    with open(\"car_dataset.csv\", 'w', encoding='utf-16') as file:\n",
        "        dict_writer = csv.DictWriter(file, columns)\n",
        "        dict_writer.writeheader()\n",
        "        dict_writer.writerows(results)\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "for x in range(400, 402):  # we have to use page number range here\n",
        "    print(f'Getting page: {x}')\n",
        "    url_links = get_products_links(x)\n",
        "    for url_link in url_links:\n",
        "        try:\n",
        "          results.append(product_info(url_link))\n",
        "        except:\n",
        "          print(url_link)\n",
        "    print(f\"total results:{len(results)}\")\n",
        "    try:\n",
        "      save_csv(results)\n",
        "    except AttributeError as err:\n",
        "        print(\"err\")\n",
        "\n",
        "# test_link = \"https://bikroy.com/en/ad/toyota-noah-power-door-pushstart-2011-for-sale-dhaka\"\n",
        "# print(product_info(test_link))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUGfrfhjDGSo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}